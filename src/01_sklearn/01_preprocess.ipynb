{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "import zipfile as zf\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "\n",
    "def CommonNeighbors(g, u, v):\n",
    "    u_neighbors = set(g.neighbors(u))\n",
    "    v_neighbors = set(g.neighbors(v))\n",
    "    return len(u_neighbors.intersection(v_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('./data/individual_links.txt', names=['source', 'destination'],sep='\\s+')\n",
    "g = nx.from_pandas_edgelist(train_csv, source='source',target='destination')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples\n",
    "edges_positive = pd.read_csv('./edges_pos_50k.csv').to_numpy()\n",
    "edges_negative = pd.read_csv('./edges_neg_50k.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(sample_list, test = False):\n",
    "    features = []\n",
    "    i = 0\n",
    "    for sample in sample_list:\n",
    "        #print(sample)\n",
    "        source = sample[0]\n",
    "        target = sample[1]\n",
    "        if test == False:\n",
    "            label = sample[2]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        feature = []\n",
    "        try:\n",
    "            i = i+1\n",
    "            print(i)\n",
    "            \n",
    "            p = CommonNeighbors(g, source, target)\n",
    "            feature.append(p)\n",
    "            \n",
    "            #p = nx.simrank_similarity(g, source, target)\n",
    "            #feature.append(p)\n",
    "            \n",
    "            preds = nx.resource_allocation_index(g, [(source, target)])\n",
    "            for u, v, p in preds:\n",
    "                feature.append(p)\n",
    "\n",
    "            preds = nx.jaccard_coefficient(g, [(source, target)])\n",
    "            for u, v, p in preds:\n",
    "                feature.append(p)\n",
    "\n",
    "            preds = nx.adamic_adar_index(g, [(source, target)])\n",
    "            for u, v, p in preds:\n",
    "                feature.append(p)\n",
    "\n",
    "            preds = nx.preferential_attachment(g, [(source, target)])\n",
    "            for u, v, p in preds:\n",
    "                feature.append(p)\n",
    "            \n",
    "            feature.append(label)  # append label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        features.append(feature)\n",
    "    print(\"features: \"+str(len(features)))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pos = generate_features(edges_positive)\n",
    "features_neg = generate_features(edges_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_pos + features_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_train_to_csv(features):\n",
    "    with open(\"train_50k.csv\",\"w\",newline=\"\") as csvfile:\n",
    "        writer=csv.writer(csvfile)\n",
    "        writer.writerow([\"CN\",\"RA\",\"JC\",\"AA\",\"PA\",\"Label\"])\n",
    "        writer.writerows(features)\n",
    "        \n",
    "write_train_to_csv(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_samples():\n",
    "    with open('./data/test-public.txt') as test:\n",
    "        test_edges = []\n",
    "        for line in test:\n",
    "            edge_list = line.split()\n",
    "            try:\n",
    "                test_edges.append((int(edge_list[1]), int(edge_list[2])))\n",
    "            except:\n",
    "                pass\n",
    "        return test_edges\n",
    "test_samples = get_test_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output label -1 for data in test set\n",
    "test_features = generate_features(test_samples, test = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_to_csv(test_features):\n",
    "    with open(\"test_50k.csv\",\"w\") as csvfile:\n",
    "        writer=csv.writer(csvfile)\n",
    "        writer.writerow([\"CN\",\"RA\",\"JC\",\"AA\",\"PA\",\"Label\"])\n",
    "        writer.writerows(test_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_test_to_csv(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf-gpu.1-15.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf-gpu.1-15:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
