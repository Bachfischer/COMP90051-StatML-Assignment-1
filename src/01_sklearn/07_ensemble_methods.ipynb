{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CN        RA        JC         AA  Label\n",
      "0      89  0.016363  0.020588  10.121960      1\n",
      "1      14  0.004045  0.006890   1.607620      1\n",
      "2       2  0.000003  0.000017   0.149925      1\n",
      "3       0  0.000000  0.000000   0.000000      1\n",
      "4       0  0.000000  0.000000   0.000000      1\n",
      "...    ..       ...       ...        ...    ...\n",
      "99995   0  0.000000  0.000000   0.000000      0\n",
      "99996   0  0.000000  0.000000   0.000000      0\n",
      "99997   0  0.000000  0.000000   0.000000      0\n",
      "99998   0  0.000000  0.000000   0.000000      0\n",
      "99999   0  0.000000  0.000000   0.000000      0\n",
      "\n",
      "[100000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier,BaggingClassifier,StackingClassifier,VotingClassifier,HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score,RepeatedStratifiedKFold\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('./data/train_50k.csv',delimiter =',')\n",
    "dataset = dataset.drop(['PA'],axis=1)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.90000000e+01, 1.63630019e-02, 2.05875549e-02, 1.01219597e+01],\n",
       "       [1.40000000e+01, 4.04548800e-03, 6.88976378e-03, 1.60762045e+00],\n",
       "       [2.00000000e+00, 3.27318232e-06, 1.67571553e-05, 1.49924838e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_SIZE=4\n",
    "X = dataset.iloc[:,0:FEATURE_SIZE].values\n",
    "y = dataset.iloc[:, FEATURE_SIZE].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16773780289600349\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "print(np.amin(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self defined scorer function, using auc.\n",
    "def scorer(estimator,X,y):\n",
    "    pre = estimator.predict_proba(x_test)\n",
    "    y_pre=[p[1] for p in pre]\n",
    "    acc=estimator.score(x_test,y_test)\n",
    "    auc=roc_auc_score(y_test,y_pre)\n",
    "    print(estimator, auc,acc)\n",
    "    #return acc\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "#test the different parameters of svm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV as gsc\n",
    "#parameters used \n",
    "parameters = {'kernel':('linear','poly', 'rbf', 'sigmoid'), 'C':[1,5,10]}\n",
    "svc = SVC(probability=True)\n",
    "clf = gsc(svc,parameters,n_jobs=-1,scoring=scorer, verbose=10)\n",
    "clf.fit(x_train,y_train)\n",
    "pre=clf.predict_proba(x_test)\n",
    "#print out the best parameters\n",
    "print(clf.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed: 20.8min remaining:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed: 29.6min remaining:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 32.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 32.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 6, 'n_estimators': 10000}\n"
     ]
    }
   ],
   "source": [
    "#test forest params using grid search\n",
    "from sklearn.model_selection import GridSearchCV as gsc\n",
    "parameters = {'n_estimators':[100,1000,10000],'min_samples_split':[2,4,6]}\n",
    "rfc = RandomForestClassifier(n_estimators=1000, max_features=\"auto\",random_state=0)\n",
    "clf = gsc(rfc,parameters,n_jobs=-1,scoring=scorer, verbose=10)\n",
    "clf.fit(x_train,y_train)\n",
    "pre=clf.predict_proba(x_test)\n",
    "#print out the best parameters\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89125\n",
      "0.9002861661402214\n"
     ]
    }
   ],
   "source": [
    "#training new features on best_params_\n",
    "svc = SVC(kernel='linear',C=10,probability=True)\n",
    "svc.fit(x_train,y_train)\n",
    "pre=svc.predict_proba(x_test)\n",
    "y_pre=[p[1] for p in pre]\n",
    "acc=svc.score(x_test,y_test)\n",
    "print(acc)\n",
    "auc=roc_auc_score(y_test,y_pre)\n",
    "print(auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81335\n",
      "0.8975497047993554\n"
     ]
    }
   ],
   "source": [
    "#test params\n",
    "svc = SVC(kernel='linear',C=10,probability=True)\n",
    "ada=AdaBoostClassifier(svc,n_estimators=5)\n",
    "ada.fit(x_train,y_train)\n",
    "pre=ada.predict_proba(x_test)\n",
    "y_pre=[p[1] for p in pre]\n",
    "acc=ada.score(x_test,y_test)\n",
    "print(acc)\n",
    "auc=roc_auc_score(y_test,y_pre)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get models for voting\n",
    "def get_voting():\n",
    "    models = list()\n",
    "    svc = SVC(kernel='linear',C=10,probability=True)\n",
    "    #models.append(('ada',AdaBoostClassifier(svc,n_estimators=4)))\n",
    "    #models.append(('bc',BaggingClassifier(base_estimator=SVC(kernel='linear',C=10,probability=True),n_estimators=10, random_state=0)))\n",
    "    models.append(('etc',ExtraTreesClassifier(n_estimators=1000, random_state=0)))\n",
    "    models.append(('gbc',GradientBoostingClassifier(random_state=0)))\n",
    "    models.append(('hgbc',HistGradientBoostingClassifier()))\n",
    "    models.append(('rfc',RandomForestClassifier(n_estimators=1000, max_features=\"auto\",random_state=0)))\n",
    "    ensemble = VotingClassifier(estimators=models,voting = 'soft')\n",
    "    return ensemble\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get models for individual testing\n",
    "def get_models():\n",
    "    models = dict() \n",
    "    svc = SVC(kernel='linear',C=10,probability=True)\n",
    "    #models['ada'] = AdaBoostClassifier(svc,n_estimators=4)\n",
    "    #models['bc'] = BaggingClassifier(base_estimator=SVC(kernel='linear',C=10,probability=True),n_estimators=10, random_state=0)\n",
    "    models['etc'] = ExtraTreesClassifier(n_estimators=10000,min_samples_split=6, random_state=0)\n",
    "    models['gbc'] = GradientBoostingClassifier(random_state=0)\n",
    "    models['hgbc'] = HistGradientBoostingClassifier()\n",
    "    models['rfc']  = RandomForestClassifier(n_estimators=10000,min_samples_split=6, max_features=\"auto\",random_state=0)\n",
    "    models['voting'] = get_voting()\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation testing on ensemble methods\n",
    "def evaluate(model,X,y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state = 0)\n",
    "    results = cross_val_score(model,X,y,scoring=scorer,cv=cv,n_jobs=-1,error_score='raise', verbose=10)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed: 24.2min remaining: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed: 24.6min remaining:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 30.5min remaining:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 30.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">etc 0.9009 (0.000)\n",
      "gbc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:   24.6s remaining:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:   28.5s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   31.3s remaining:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   31.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">gbc 0.9016 (0.000)\n",
      "hgbc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:    4.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:    5.1s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    6.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">hgbc 0.9017 (0.000)\n",
      "rfc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 12.1min\n"
     ]
    }
   ],
   "source": [
    "#main and print for acores\n",
    "models = get_models()\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    scores = evaluate(model,x_train,y_train)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.4f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "pyplot.boxplot(results,labels=names,showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprob_predictions = [y_pre_ada,y_pre_rfc,y_pre_gbc,y_pre_bc,y_pre_etc,y_pre_hgbc]\\nensemble_pred = [sum(x)/len(x) for x in zip(*prob_predictions)]\\nauc = roc_auc_score(y_test,ensemble_pred)\\nprint(auc)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "prob_predictions = [y_pre_ada,y_pre_rfc,y_pre_gbc,y_pre_bc,y_pre_etc,y_pre_hgbc]\n",
    "ensemble_pred = [sum(x)/len(x) for x in zip(*prob_predictions)]\n",
    "auc = roc_auc_score(y_test,ensemble_pred)\n",
    "print(auc)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('ada', AdaBoostClassifier(n_estimators=1000)),\n",
      "                             ('etc',\n",
      "                              ExtraTreesClassifier(n_estimators=1000,\n",
      "                                                   random_state=0)),\n",
      "                             ('gbc',\n",
      "                              GradientBoostingClassifier(random_state=0)),\n",
      "                             ('hgbc', HistGradientBoostingClassifier()),\n",
      "                             ('rfc',\n",
      "                              RandomForestClassifier(n_estimators=1000,\n",
      "                                                     random_state=0))],\n",
      "                 voting='soft') 0.9015960617820703 0.89335\n"
     ]
    }
   ],
   "source": [
    "#train the ensemble methods via voting and validate\n",
    "ensemble = get_voting()\n",
    "ensemble.fit(x_train,y_train)\n",
    "pre = ensemble.predict_proba(x_test)\n",
    "y_pre=[p[1] for p in pre]\n",
    "acc=ensemble.score(x_test,y_test)\n",
    "auc=roc_auc_score(y_test,y_pre)\n",
    "print(ensemble, auc,acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform final test on kaggle data\n",
    "testdata = pd.read_csv('./data/test_50k.csv')\n",
    "x_testing = testdata.iloc[:,0:FEATURE_SIZE].values \n",
    "x_testing = sc.transform(x_testing)\n",
    "predictions=ensemble.predict_proba(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print kaggle data to file.\n",
    "import csv\n",
    "with open(\"./data/kaggle.csv\",\"w\",newline=\"\") as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow([\"Id\",\"Predicted\"])\n",
    "    test_id=1\n",
    "    for prediction in predictions:\n",
    "        writer.writerow([test_id,prediction[1]])\n",
    "        test_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
